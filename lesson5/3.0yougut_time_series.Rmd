***
### Sean's NFL Fan Sentiment Study
Count ratios of positive to negative words with five minutes increaments.  
End up with a series that is too noisy to tell a story. So we aggregate it up to one day moving averages, then we start to see some patterns emerge.

Wanna predict sentiment as a function of fan's sentiment.  
First using natural spline, to is cannot tell to story of win and loss on game day, the you are much happier or sadder than the beginning of the game. So we expect to see sentiment jumps that we don't see from a model like this.

Then using *seven day moving average* which just allow us to include the last game sentient in the moving average. Then smoooth it out over whole seven day period. This really tells a good story. Then it gives us the discreteness that we want. 
***

### Introducing the Yogurt Data Set
Notes:
```{r}
library(ggplot2)
library(dplyr)
yo<-read.csv('yogurt.csv')
yo$id<-factor(yo$id)
head(yo)
str(yo)
summary(yo)
names(yo)
```

***

### Histograms Revisited
We can notice the discreteness of this distribution.
No observations in adjacent prices.  
This prices are set in a way that applies to many of the consumers  

As we increase the binwidth, the plot model will be biased.
```{r Histograms Revisited}
ggplot(data=yo,
       aes(x=price))+
  geom_histogram(binwidth = 5,
                 fill='orange')+
  scale_x_continuous(breaks=seq(0,80,5))

```

***

### Number of Yogurt Purchases

```{r Number of Purchases}
length(unique(yo$price))
yo<-mutate(yo,all.purchase=
              strawberry+blueberry+
              pina.colada+plain+mixed.berry)
summary(yo$all.purchase)
ggplot(data=yo,
       aes(x=all.purchase))+
  geom_histogram(binwidth = 1)
```

***

### Prices over Time
we have data of the same households over time  
```{r Prices over Time}
length(unique(yo$id))  #number of users
length(yo$id) #number of buying behavior

ggplot(data=yo,
       aes(x=time,y=price))+
  geom_jitter(alpha=1/5,shape=3,color='brown')
#The most common prices seem to be increasing over time.
#Lower prices may because buyers using coupons that bring down the prices.
```


### Looking at Samples of Households
x %in% y returns a logical (boolean) vector the same length as x that says whether each entry in x appears in y. That is, for each entry in x, it checks to see whether it is in y.   
[Graphical Parameters](http://www.statmethods.net/advgraphs/parameters.html)
```{r Looking at Sample of Households}
#set the seed for reproducible results
#This allows us to subset the data so we get all the purchases occasions for the households in the sample. Then, we create scatterplots of price vs. time and facet by the sample id. 
set.seed(4230)
length(levels(yo$id))
sample.ids<-sample(levels(yo$id),9,replace = FALSE)

#Use the pch or shape parameter to specify the symbol when plotting points. Scroll down to 'Plotting Points' #We could 
ggplot(data=filter(yo,id %in% sample.ids),
       aes(x=time,y=price))+
  facet_wrap(~id)+
  geom_point(aes(size=all.purchase),pch=1)+
  geom_line(lty=2,col='brown')
#facet_wrap---set the color 

```
The plot indicates that some household purchases more quantities than others.  
For most households, the price of yogurt holds steady.
***

### The Limits of Cross Sectional Data
The general idea is we have observations over time , we can facet by primary unit, case, or individual.
*Facet time series data* can't generated by our pseudo_facebook dataset. Since we don't have data on our sample of users over time, in which every observation is one snapshot at a fixed point that tell us the characteristic of individuals. Not individuals over a year.