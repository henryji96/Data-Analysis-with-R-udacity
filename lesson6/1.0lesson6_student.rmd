
### Scatterplot Review

```{r Scatterplot Review}
library(ggplot2)
library(dplyr)
ggplot(data=diamonds,
       aes(x=carat,y=price))+
  geom_point(alpha=1/20,fill='brown',shape=21)+
  xlim(0,quantile(diamonds$carat,0.99))+
  ylim(0,quantile(diamonds$price,0.99))+
  geom_smooth(method='lm')
```
We can see that the linear trend line doesn't go through the center of the data at some key places. It misses it here. It should curve a little bit in the center of the relationship, and it should slope up more toward the end. And if we tried to use this to make predictions, we might be off for some key
***

### Price and Carat Relationship

1. We can see a nonlinear realtionship, maybe it's expoential.
2. We can see that the dispersion or variance of the relationship also increases as carat size increases. 

***
### ggpairs Function
This function plots each variable against each other variable, pairwise. You may want to sample first, otherwise the function will take a long time to render the plots. Also, if your data set has more than about 10 columns, there will be too many plotting windows. So, subset on your columns first if that's the case.
We use *ggally* for this particular plot.   
We use *scales* for a variety of things.
*memisc* to summarize the regression.
*lattice* for few other things.
*mass* for various functions. 
*car* to recode variables. 
*reshape* to reshape and wrangle your data. 
*plyr* to create interesting summaries and transmissions that you've done.
```{r ggpairs Function}
# install these if necessary
#install.packages('GGally')
#install.packages('scales')
#install.packages('memisc')
#install.packages('lattice')
#install.packages('MASS')
#install.packages('car')
#install.packages('reshape')
#install.packages('plyr')

# load the ggplot graphics package and the others
library(ggplot2)
library(GGally)
library(scales)
library(memisc)

# sample 10,000 diamonds from the data set
set.seed(20022012)
diamond_samp <- diamonds[sample(1:length(diamonds$price), 10000), ]
ggpairs(diamond_samp, 
  lower = list(continuous = wrap("points", shape = I('.'))), 
  upper = list(combo = wrap("box", outlier.shape = I('.'))))
```
ggpairs is plotting each variable against the other in a pretty smart way.    
In the lower triangle of the plot matrix, it uses *grouped histograms* for qualitative, qualitative pairs and *scatter plots* for quantitative, quantitative pairs.    
The upper triangle, it plots *grouped histograms* for qualitative, qualitative pairs, this time using the x instead of the y variable as the grouping factor. *Box plots* for qualitative, quantitative pairs, and it provides *the correlation* for quantitative quantitative pairs.  


What are some things you notice in the ggpairs output?
Response:

***

### The Demand of Diamonds
https://www.r-statistics.com/2013/05/log-transformations-for-skewed-and-wide-distributions-from-practical-data-science-with-r/

On the demand side, customers in the market for a less expensive, smaller diamond are probably more sensitive to price than more well-to-do buyers. 
And there are fewer customers who can afford a bigger diamond that is one that is larger than than one carat, hence we shouldn't expect the market for bigger diamonds to be as competitive as the one for smaller diamonds. So it makes sense that the variants as well as the price would increase with carat size. 
Now often the distribution of any monetary variable like
dollars will be highly skewed and vary over orders of magnitude. Now this can result from *path dependence* for example the rich getting richer, or *multiplicative processes* like year on year inflation, or some combination of both. Hence it's a good idea to look into compressing any such variable by putting it on a log scale.
```{r The Demand of Diamonds}
library(gridExtra)
library(ggplot2)

p1<-ggplot(data=diamonds,aes(x=price))+
  geom_histogram(binwidth=100,fill='yellow')+
  ggtitle('Price')

p2<-ggplot(data=diamonds,aes(x=price))+
  geom_histogram(binwidth=0.01,fill='blue')+
  ggtitle('Price')+
  scale_x_log10()


grid.arrange(p1,p2,ncol=2)
```
We can see that the prices for diamonds are highly skewed, but when you put those prices on a log ten scale, they seem much better behaved. They're much closer to the bell curve of a normal distribution. 
We can even see a little bit of evidence of bimodality on this log10 scale. Which is consistent with our two class rich buyer poor buyer speculation about the nature of customers for diamonds.
***
### Create a new function to transform the carat variable

```{r cuberoot transformation}
cuberoot_trans<-function() trans_new('cuberoot',
                                     transform = function(x) x^(1/3),
                                     inverse = function(x) x^3)

cuberoot_trans
```

#### Use the cuberoot_trans function
### Overplotting Revisited
set alpha,size,jitter
```{r Sort and Head Tables}
ggplot(data=diamonds,aes(carat,price))+
  geom_point(alpha=0.5,size=0.75,position='jitter')+ 
  scale_x_continuous(trans = cuberoot_trans(), 
                     limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), limits = c(350, 15000),
                     breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat')
  
```


### Price vs. Carat and Clarity
http://ggplot2.tidyverse.org/reference/scale_brewer.html

```{r Price vs. Carat and Clarity}
# install and load the RColorBrewer package
#install.packages('RColorBrewer')
library(RColorBrewer)

ggplot(aes(x = carat, y = price,colour=clarity), data = diamonds) + 
  geom_point(alpha = 0.5, size = 1, position = 'jitter') +
  scale_color_brewer(type = 'div',
    guide = guide_legend(title = 'Clarity', reverse = T,
    override.aes = list(alpha = 0.9, size = 3))) +  
  scale_x_continuous(trans=cuberoot_trans(), 
                     limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3))+
  scale_y_log10( limits = c(350, 15000),
    breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat and Clarity')
```
We saw that diamonds woth lower clarity are always cheaper than diamonds with better clarity.

### Price vs. Carat and Cut

Alter the code below.
```{r Price vs. Carat and Cut}
ggplot(aes(x = carat, y = price, color = cut), 
       data = diamonds) + 
  geom_point(alpha = 0.5, size = 1, position = 'jitter') +
  scale_color_brewer(type = 'div',
                     guide = guide_legend(title = 'Cut', 
                                          reverse = T,
                                          override.aes = list(alpha = 1,
                                                              size = 2))) +  
  scale_x_continuous(trans = cuberoot_trans(), 
                     limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), 
                     limits = c(350, 15000),
                     breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat and Cut')
```
Most diamonds in the data are cut ideally, so we lose the color pattern saw before.

### Price vs. Carat and Color

Alter the code below.
```{r Price vs. Carat and Color}
ggplot(aes(x = carat, y = price), 
       data = diamonds) + 
  geom_point(alpha = 0.5, size = 1, 
             position = 'jitter',
             aes(color=color)) +
  scale_color_brewer(type = 'div',
                     palette = 2,   #color
                     guide = guide_legend(title = 'Color', 
                                          reverse = F,
                                          override.aes = list(alpha = 1, size = 2))) +  
  scale_x_continuous(trans = cuberoot_trans(), limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), limits = c(350, 15000),
                     breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat and Color')
```
We do find the color difference in the color type.
reverse=F means the best color would be at the top of the list in the legend.

### Linear Models in R
lm(y~x)
y is the outcome variable  
x is the explanatory variable 

+ We apply log transformation to our long tailed price variable   
+ We speculate that the flawless diamonds will become expoentially rare as diamond volumns increase. So we should be intreasted in the cube root of our carat variable.
+ log(price)~carat^(1/3)
***

### Building the Linear Model
*I* stands for 'as it is', it tells R to use the expression inside the I function to transform a variable before using it in the regression. This is instead of instructing R to interpret these symbols as part of the formula to construct the design matrix for the regression.   
I can also update the previous model to add the carat variable in the regression, using the syntax. The real functional relationship is surely not as simple as the cubed root of carat, so we add a simple linear function of carat in our model predicting price. And we can continue to make more complex models by adding more variables. 

http://blog.yhathq.com/posts/r-lm-summary.html
http://www.theanalysisfactor.com/interpreting-regression-coefficients/
http://www.r-bloggers.com/interpreting-regression-coefficient-in-r/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+RBloggers+%28R+bloggers%29
https://stats.stackexchange.com/questions/24242/how-to-apply-coefficient-term-for-factors-and-interactive-terms-in-a-linear-equa/24256#24256
```{r Building the Linear Model}
m1 <- lm(I(log(price)) ~ I(carat^(1/3)), data = diamonds)
m2 <- update(m1, ~ . + carat)
m3 <- update(m2, ~ . + cut)
m4 <- update(m3, ~ . + color)
m5 <- update(m4, ~ . + clarity)
mtable(m1, m2, m3, m4, m5,sdigits = 3)
```

Notice how adding cut to our model does not help explain much of the variance
in the price of diamonds. This fits with out exploration earlier.

Our model is    
**lm(price)=0.415+9.144carat^(1/3)-1.093carat+(...cut+...color+...clarity)+error**

### Model Problems
To start, our data's from 2008. So, not only do we need to account for inflation, but the diamond market is quite different now than it was. In fact, when I fit models to this data and predicted the price of the diamonds that I found off a market, I kept getting predictions that were way too
low. 
After some additional digging, I found that global diamonds were poor. It turns out that prices plummeted in 2008 due to the global financial crisis. And since then prices, at least for wholesale polished diamonds, have grown about 6% a year,compound annual rate. 
The rapid growing number of couples in China buying diamond engagement rings might also explain this increase. 
And finally, after looking at the data on price scope, I realize that diamond prices grew unevenly across different carat sizes since 2008, meaning that the model I initially estimated couldn't simply be adjusted by inflation.

## Building a Model Using the Big Diamonds Data Set
```{r}
library(dplyr)
diamondsbig<-read.csv("diamondsbig.csv")
```
```{r}
dim(diamondsbig)
diamondsbig$logprice=log(diamondsbig$price)
dbig<-diamondsbig %>%
  filter(price<10000,cert=="GIA")
dim(dbig)
```

```{r Building a Model Using the Big Diamonds Data Set}
m1 <- lm(logprice ~ I(carat^(1/3)), 
         data = dbig)
m2 <- update(m1, ~ . + carat)
m3 <- update(m2, ~ . + cut)
m4 <- update(m3, ~ . + color)
m5 <- update(m4, ~ . + clarity)
mtable(m1,m2,m3,m4,m5)
```
Our models look quite like they did for the small dataset.
```{r}
m5$coefficients
mean(m5$residuals)
m5$model
```

***

## Predictions
https://en.wikipedia.org/wiki/Confidence_interval
Example Diamond from BlueNile:
Round 1.00 Very Good I VS1 $5,601

```{r}
#Be sure youâ€™ve loaded the library memisc and have m5 saved as an object in your workspace.
thisDiamond = data.frame(carat = 1.00, cut = "V.Good",
                         color = "I", clarity="VS1")
modelEstimate = predict(m5, newdata = thisDiamond,
                        interval="prediction", level = .95)
exp(modelEstimate)
```

Evaluate how well the model predicts the BlueNile diamond's price. Think about the fitted point estimate as well as the 95% CI.
```{r}
round(
  0.87600,2
)
```

As carat increases, the predicted residuals increase.
```{r}
dat = data.frame(m4$model, m4$residuals) 
dim(dat)
dim(m4$model)
length(m4$residuals)
head(dat)
str(dat$m4.residuals)

with(dat, sd(m4.residuals)) 

with(subset(dat, carat > .9 & carat < 1.1), sd(m4.residuals)) 

dat$resid <- as.numeric(dat$m4.residuals)
ggplot(aes(y = resid, x = round(carat, 2)), 
       data = dat) + 
  geom_line(stat = "summary", fun.y = sd) 
```

